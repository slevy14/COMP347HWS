{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "GXmqHl_K3YMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### IMPORTS\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "cwFlW9J977u5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K62Awyvl3TzP"
      },
      "outputs": [],
      "source": [
        "### EQUATION 1 SHOULD HAVE A \"+\" BEFORE THE SUM\n",
        "\n",
        "def RegressionAtHome(X_train, Y_train, x_pred, tau):\n",
        "\n",
        "\n",
        "# Gradient is first partial derivatives of the cost function\n",
        "# Hessian Matrix is second partial derivatives of the cost function\n",
        "# Newton's method uses\n",
        "\n",
        "def magnitude(vector):\n",
        "    return math.sqrt(sum(pow(element, 2) for element in vector))\n",
        "\n",
        "def calc_weight(x_q, x_i, tau):\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2"
      ],
      "metadata": {
        "id": "8ie4ZCHk4yPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Soft-Margin Linear SVM, C=.02 corresponds to #4. This is a linear model with larger margins, so the C value is lower.\n",
        "2. Soft-Margin Linear SVM, C=20 corresponds to #3. This is a linear model with smaller margins, so the C value is higher.\n",
        "3."
      ],
      "metadata": {
        "id": "YkZeGtQD402u"
      }
    }
  ]
}